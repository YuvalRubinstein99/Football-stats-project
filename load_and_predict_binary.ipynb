{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction #\n",
    "\n",
    "After a first check on the data, using ordinal regressions and linear regressions, we can add new variables we've seen can help with prediction and use them with more complex models such as tree based or mlp models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import feature_selection\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error,roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression, PoissonRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, IsolationForest\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import pickle\n",
    "from difflib import SequenceMatcher\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def third_largest(row):\n",
    "    sorted_row = sorted(row, reverse=True)\n",
    "    return sorted_row[2] if len(sorted_row) >= 3 else None\n",
    "\n",
    "def third_smallest(row):\n",
    "    sorted_row = sorted(row)\n",
    "    return sorted_row[2] if len(sorted_row) >= 3 else None\n",
    "\n",
    "def get_data_cols(df, att, prefix):\n",
    "    '''\n",
    "    Gets an attribute, and adds columns to show mean, max, min and sd (ignoring zeros) for the first num_players players.\n",
    "\n",
    "    Parameters:\n",
    "    df : The dataframe\n",
    "    att: which attribute (e.g., Weight)\n",
    "    prefix: HomePlayer or AwayPlayer\n",
    "    '''\n",
    "\n",
    "    player_weight_cols = [col for col in df.columns if col.startswith(f\"{prefix}\") and col.endswith(f\"_{att}\")]\n",
    "    att = att.replace('(', ' ')\n",
    "    if not player_weight_cols:\n",
    "        print('no col with', att)\n",
    "        return df\n",
    "\n",
    "    # Select only the columns corresponding to the first num_players players\n",
    "    player_weight_cols_subset = player_weight_cols[:11]  # Selecting the first 11 players\n",
    "\n",
    "    # Replace zeros with NaN\n",
    "    df[player_weight_cols_subset] = df[player_weight_cols_subset].replace(0, np.nan)\n",
    "\n",
    "\n",
    "    if(att == 'Overall'):\n",
    "        df[f\"{prefix}_{att}_max\"] = df[player_weight_cols_subset].max(axis=1, skipna=True)\n",
    "        df[f\"{prefix}_{att}_min\"] = df[player_weight_cols_subset].min(axis=1, skipna=True)\n",
    "        df[f\"{prefix}_{att}_sd\"] = df[player_weight_cols_subset].std(axis=1, skipna=True)\n",
    "        df[f\"{prefix}_{att}_mean\"] = df[player_weight_cols_subset].mean(axis=1, skipna=True)\n",
    "        df[f\"{prefix}_{att}_mean_ln\"] = np.log(df[player_weight_cols_subset]).mean(axis=1, skipna=True)\n",
    "        df[f\"{prefix}_{att}_mean_sqrt\"] = np.sqrt(df[player_weight_cols_subset]).mean(axis=1, skipna=True)\n",
    "        df[f\"{prefix}_3rd_best\"] = df[player_weight_cols_subset].apply(third_largest, axis=1)\n",
    "        df[f\"{prefix}_3rd_worst\"] = df[player_weight_cols_subset].apply(third_smallest, axis=1)\n",
    "\n",
    "\n",
    "  \n",
    "    if(' ' in att): # 2 worded attributes so instead of dribbling total we will have dribbling\n",
    "        df[f\"{prefix}_{att.split()[0]}_mean\"] = df[player_weight_cols_subset].mean(axis=1, skipna=True)\n",
    "\n",
    "    else:\n",
    "        df[f\"{prefix}_{att}_mean\"] = df[player_weight_cols_subset].mean(axis=1, skipna=True)\n",
    "\n",
    "\n",
    "    return df\n",
    "def find_most_similar_name(target_name, names_list, threshold=0.25):\n",
    "    similarities = [(other_name, SequenceMatcher(None, target_name, other_name).ratio()) for other_name in names_list]\n",
    "    if (len(similarities) == 0):\n",
    "        return None, None\n",
    "    most_similar_name, similarity_score = max(similarities, key=lambda x: x[1])\n",
    "    \n",
    "    if similarity_score >= threshold:\n",
    "        #print('found player '+most_similar_name+\" with a score of \"+str(similarity_score))\n",
    "        return most_similar_name, similarity_score\n",
    "    else:\n",
    "        print(\"didn't find\", target_name)\n",
    "        return None, None\n",
    "def find_player(player_name, club_name,  df, attributes):\n",
    "    #first we filter by club name\n",
    "    temp = df[df['Club Name'] == club_name]\n",
    "\n",
    "    #Now we find the player\n",
    "    sim_name, full_score = find_most_similar_name(player_name, temp['Full Name'])\n",
    "    sim_nickname, short_score = find_most_similar_name(player_name, temp['Known As'])\n",
    "    if sim_name: # there is a full name\n",
    "        ## if there is a nickname we have to check\n",
    "        if sim_nickname and full_score > short_score:\n",
    "            print('found plauyer',sim_name)\n",
    "            return temp[temp['Full Name'] == sim_name].iloc[0][attributes]\n",
    "            \n",
    "        elif sim_nickname:\n",
    "            print('found plauyer',sim_nickname)\n",
    "            return temp[temp['Known As'] == sim_nickname].iloc[0][attributes]\n",
    "        print('found plauyer',sim_name)\n",
    "\n",
    "        return temp[temp['Full Name'] == sim_name].iloc[0][attributes]\n",
    "        \n",
    "    if sim_nickname: # if there is a nickname but no full name\n",
    "        print('found plauyer',sim_nickname)\n",
    "        return temp[temp['Known As'] == sim_nickname].iloc[0][attributes]\n",
    "\n",
    "    print(\"didn't find\", player_name)\n",
    "    return None\n",
    "\n",
    "\n",
    "def ratings_col(df, att_df):\n",
    "    '''\n",
    "    puts for every player their 'Overall', 'Age', 'Height(in cm)', 'Weight(in kg)'\n",
    "    for each player i we will have the column\n",
    "    HomePlayeri (if the player is on the home team)\n",
    "    AwayPlayeri (if the player is on the away team)\n",
    "    and we will use the home_team_name or away_team_name and the full name as the key (we will use find_player(player_name, club_name,  df, attributes))\n",
    "    '''\n",
    "\n",
    "    attributes = [ 'Overall']\n",
    "    # Iterate through each player column\n",
    "    for i in range(1, 12):\n",
    "\n",
    "        home_col = f'HomePlayer{i}'\n",
    "        away_col = f'AwayPlayer{i}'\n",
    "        if home_col in df.columns or away_col in df.columns:\n",
    "            # Add columns for home team players\n",
    "            for att in attributes:\n",
    "                \n",
    "                df[home_col + \"_\" + att] = df.apply(\n",
    "                    lambda row: (find_player(row[home_col], row['home_team_name'], att_df, attributes)[att]\n",
    "                                 if isinstance(row[home_col], str) and find_player(row[home_col], row['home_team_name'], att_df, attributes) is not None \n",
    "                                 else row[home_col]) if not pd.isna(row[home_col]) else 0,\n",
    "                    axis=1\n",
    "                )\n",
    "\n",
    "            for att in attributes:\n",
    "                df[away_col + \"_\" + att] = df.apply(\n",
    "                    lambda row: (find_player(row[away_col], row['away_team_name'], att_df, attributes)[att]\n",
    "                                 if isinstance(row[away_col], str) and find_player(row[away_col], row['away_team_name'], att_df, attributes) is not None \n",
    "                                 else row[away_col]) if not pd.isna(row[away_col]) else 0,\n",
    "                    axis=1\n",
    "                )\n",
    "def replace_nas(df):\n",
    "    '''\n",
    "    gets df, goes to the Age column and replaces None with 18, and replaces Weight(in kg) and Height(in cm) with the mean, and overall with the min value\n",
    "    '''\n",
    "\n",
    "    # 'Dribbling Total', 'Pace Total', 'Defending Total', 'Shooting Total', 'Physicality Total', 'Passing Total' our new fatures\n",
    "    attributes = ['Overall']\n",
    "    # First, deal with the None values\n",
    "    for i in range(1,12):\n",
    "        home_col = f'HomePlayer{i}'\n",
    "        away_col = f'AwayPlayer{i}'\n",
    "        if home_col in df.columns:\n",
    "            #\n",
    "            for att  in attributes: \n",
    "                non_zero_col = df[home_col+'_'+att].replace(0, None)\n",
    "                df[home_col+'_'+att].fillna(non_zero_col.min())\n",
    "        if away_col in df.columns:\n",
    "\n",
    "            for att  in attributes: \n",
    "                non_zero_col = df[away_col+'_'+att].replace(0, None)\n",
    "                df[away_col+'_'+att].fillna(non_zero_col.min())\n",
    "            # df[home_col+\"_Age\"].fillna(18, inplace=True)\n",
    "            \n",
    "            # # dealing with some ratings\n",
    "\n",
    "            # df[home_col+\"_Total\"].fillna(18, inplace=True)\n",
    "            # df[home_col+\"_Dribbling Total\"].fillna(df[home_col+\"_Dribbling Total\"].replace(0,None).min(), inplace=True)\n",
    "            # df[home_col+\"_Defending Total\"].fillna(df[home_col+\"_Defending Total\"].replace(0,None).min(), inplace=True)\n",
    "            # df[home_col+\"_Shooting Total\"].fillna(df[home_col+\"_Shooting Total\"].replace(0,None).min(), inplace=True)\n",
    "            # df[home_col+\"_Physicality Total\"].fillna(df[home_col+\"_Physicality Total\"].replace(0,None).min(), inplace=True)\n",
    "            # df[home_col+\"_Pace Total\"].fillna(df[home_col+\"_Pace Total\"].replace(0,None).min(), inplace=True)\n",
    "\n",
    "            # # Build assumption (ignoring zeros)\n",
    "            # non_zero_weights = df[home_col+\"_Weight(in kg)\"].replace(0, None)\n",
    "            # non_zero_heights = df[home_col+\"_Height(in cm)\"].replace(0, None)\n",
    "            # non_zero_overall = df[home_col+\"_Overall\"].replace(0, None)\n",
    "            # df[home_col+\"_Weight\"].fillna(non_zero_weights.mean(), inplace=True)\n",
    "            # df[home_col+\"_Height\"].fillna(non_zero_heights.mean(), inplace=True)\n",
    "            \n",
    "            \n",
    "            # # Ratings assumption\n",
    "            # df[home_col+\"_Overall\"].fillna(non_zero_overall.min(), inplace=True)\n",
    "            \n",
    "            # # And for away\n",
    "            # # Age assumption\n",
    "            # df[away_col+\"_Age\"].fillna(18, inplace=True)\n",
    "\n",
    "            # df[away_col+\"_Total\"].fillna(18, inplace=True)\n",
    "            # df[away_col+\"_Dribbling Total\"].fillna(df[away_col+\"_Dribbling Total\"].replace(0,None).min(), inplace=True)\n",
    "            # df[away_col+\"_Defending Total\"].fillna(df[away_col+\"_Defending Total\"].replace(0,None).min(), inplace=True)\n",
    "            # df[away_col+\"_Shooting Total\"].fillna(df[away_col+\"_Shooting Total\"].replace(0,None).min(), inplace=True)\n",
    "            # df[away_col+\"_Physicality Total\"].fillna(df[away_col+\"_Physicality Total\"].replace(0,None).min(), inplace=True)\n",
    "            # df[away_col+\"_Pace Total\"].fillna(df[away_col+\"_Pace Total\"].replace(0,None).min(), inplace=True)\n",
    "\n",
    "            # # Build assumption (ignoring zeros)\n",
    "            # non_zero_weights_away = df[away_col+\"_Weight\"].replace(0, None)\n",
    "            # non_zero_heights_away = df[away_col+\"_Height\"].replace(0, None)\n",
    "            # non_zero_overall_away = df[away_col+\"_Overall\"].replace(0, None)\n",
    "            # df[away_col+\"_Weight\"].fillna(non_zero_weights_away.mean(), inplace=True)\n",
    "            # df[away_col+\"_Height\"].fillna(non_zero_heights_away.mean(), inplace=True)\n",
    "            \n",
    "            # # Ratings assumption\n",
    "            # df[away_col+\"_Overall\"].fillna(non_zero_overall_away.min(), inplace=True)\n",
    "            \n",
    "\n",
    "    # Dealing with zero values\n",
    "    for i in range(1, 12):\n",
    "        home_col = f'HomePlayer{i}'\n",
    "        away_col = f'AwayPlayer{i}'\n",
    "        if home_col in df.columns:\n",
    "            for att in attributes:\n",
    "                df[home_col+\"_\"+att].replace(0, None, inplace=True)\n",
    "        if away_col in df.columns:\n",
    "            for att in attributes:\n",
    "                df[away_col+\"_\"+att].replace(0, None, inplace=True)\n",
    "     \n",
    "def set_season_cols(columns, season):\n",
    "    for c in season.columns:\n",
    "        for att in ['Overall']:\n",
    "            if att in c:\n",
    "                columns.append(c)\n",
    "    \n",
    "def find_closest_name(name, other_names):\n",
    "    checked = []\n",
    "    for other_name in other_names:\n",
    "        if other_name in checked:\n",
    "            continue\n",
    "        if(isinstance(other_name, float)):\n",
    "            continue\n",
    "        if name in other_name:\n",
    "            return other_name\n",
    "\n",
    "def pipeline(train_arr, fifa):\n",
    "    train_df = pd.read_csv(train_arr, encoding='latin1')\n",
    "    ratings_df = pd.read_csv(fifa,encoding='latin1')\n",
    "    ratings_df.rename(columns={'long_name' : 'Full Name', 'height_cm':'Height(in cm)',\n",
    "                          'weight_kg' : 'Weight(in kg)',\n",
    "                          'age' : 'Age', 'club_name' :\"Club Name\",\n",
    "                          'Team' : 'Club Name',\n",
    "                          'overall' : 'Overall', 'dribbling' : 'Dribbling Total',\n",
    "                          'pace' : 'Pace Total', 'defending' : \"Defending Total\" ,\n",
    "                          \"shooting\" : 'Shooting Total', 'physic' : 'Physicality Total',\n",
    "                          'passing' : \"Passing Total\", 'short_name' : 'Known As'},inplace=True)\n",
    "    print(ratings_df.columns)\n",
    "    #first we replace the names with the numbers\n",
    "    # fix_html_col(ratings_df, 'away_fromation')\n",
    "    # fix_html_col(ratings_df, 'home_formation')\n",
    "\n",
    "    # Define a dictionary\n",
    "    fifa_team_names = ratings_df['Club Name'].values\n",
    "    checked = []\n",
    "    not_found = []\n",
    "    names_fix = {'Celta Vigo': 'RC Celta de Vigo'\n",
    "                 , 'Atlético Madrid': 'Atlético de Madrid'\n",
    "                 , 'Bayern Munich': 'FC Bayern München'\n",
    "                 , 'Eint Frankfurt': 'Eintracht Frankfurt'\n",
    "                 , 'Gladbach': 'Borussia Mönchengladbach',\n",
    "                 'Sporting Gijón':'Real Sporting de Gijón',\n",
    "                 'Man Utd': \"Manchester United\",\n",
    "             \"Man City\": 'Manchester City',\n",
    "             \"West Ham\": \"West Ham United\",\n",
    "             \"Nott'm Forest\": \"Nottingham Forest\",\n",
    "             'Spurs': \"Tottenham Hotspur\",\n",
    "             'Wolves': \"Wolverhampton Wanderers\",\n",
    "             \"Brighton and Hove Albion\": \"Brighton & Hove Albion\",\n",
    "             \"Bournemouth\": \"AFC Bournemouth\",\n",
    "             'Newcastle': 'Newcastle United',\n",
    "             'Leicester': 'Leicester City',\n",
    "             'Leeds': \"Leeds United\",\n",
    "             'Huddersfield' : 'Huddersfield Town',\n",
    "             'Swansea' : 'Swansea City',\n",
    "             'Cardiff': 'Cardiff City',\n",
    "             'Norwich' : 'Norwich City',\n",
    "             'Stoke' : 'Stoke City',\n",
    "             'West Brom' : 'West Bromwich Albion',\n",
    "             'Hull' : 'Hull City',\n",
    "             'QPR' : 'Queens Park Rangers',\n",
    "             'Sheffield Utd' : 'Sheffield United'}\n",
    "    \n",
    "    for team in train_df['home_team_name'].values:\n",
    "        \n",
    "        if (team not in fifa_team_names and team not in checked) and team not in names_fix.keys():\n",
    "            checked.append(team)\n",
    "            #print(team+\" not found\")\n",
    "            \n",
    "            alt = find_closest_name(team, fifa_team_names)\n",
    "            if(alt):\n",
    "                print(team+\" can be replaced with \"+alt)\n",
    "                names_fix[team] = alt\n",
    "            else:\n",
    "                not_found.append(team)\n",
    "\n",
    "    print(not_found)\n",
    "    for key in names_fix.keys():\n",
    "        ratings_df['Club Name'].replace(names_fix[key],key, inplace=True)    \n",
    " \n",
    "    print(\"Finished Loading test\")\n",
    "    # print(train_df.columns)\n",
    "    att_list = ['Overall']\n",
    "    numerical_cols = []\n",
    "    statistic_list = ['mean', 'min', 'max', 'sd', '3rd_best', '3rd_worst']\n",
    "    #statistic_list = ['mean' ,'sd']\n",
    "    cat_cols=['home_team_name', 'away_team_name']\n",
    "\n",
    "    \n",
    "    att_list = ['Overall']\n",
    "    for att in att_list:\n",
    "        if att not in ratings_df.columns:\n",
    "            print('fix',att)\n",
    "    \n",
    "    # Sanity Check\n",
    "    ratings_df = ratings_df[['Full Name', 'Club Name', 'Known As']+ att_list]\n",
    "    ratings_col(train_df, ratings_df)\n",
    "\n",
    "    replace_nas(train_df)\n",
    "    train_df['Matchweek'] = train_df['Matchweek'].str.split(' ').str[1].astype(int)\n",
    "\n",
    "    final_cols = ['league', 'home_score', 'home_team_name', 'away_score', 'away_team_name', 'home_GD_prior', 'away_GD_prior', 'home_Points_prior', 'away_Points_prior']\n",
    "    set_season_cols(final_cols, train_df)\n",
    "\n",
    "    \n",
    "    #binary_cols = ['Home_Adv_Team', 'Strong_Away'] ## From ar\n",
    "    \n",
    "\n",
    "    for att in att_list:\n",
    "        get_data_cols(train_df, att, prefix='HomePlayer')\n",
    "        get_data_cols(train_df, att, prefix='AwayPlayer')\n",
    "    \n",
    "    for col in train_df.columns:\n",
    "        for s in statistic_list:\n",
    "            if s in col:\n",
    "                numerical_cols.append(col)\n",
    "\n",
    "    cat_cols=['Unnamed: 0', 'home_team_name', 'away_team_name', 'home_GD_prior', \n",
    "              'home_Points_prior', 'home_GD_form', 'home_Points_form', \n",
    "                'away_GD_prior', 'away_Points_prior', 'away_GD_form', \n",
    "                'away_Points_form','league', 'B365A', 'B365D', 'B365H', 'Matchweek']\n",
    "    print('finished pipeline')\n",
    "    return train_df[numerical_cols + cat_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skellam\n",
    "\n",
    "def extract_poisson_probas(home_pred, away_pred):\n",
    "    '''\n",
    "    creates a probability matrix according to the regression\n",
    "\n",
    "    Parameters:\n",
    "    home_pred: expected home score\n",
    "    away_pred: expected away score\n",
    "    '''\n",
    "\n",
    "    probability_matrix = np.zeros((len(home_pred), 3))  # 3 columns (-1, 0, 1 probabilities)\n",
    "    \n",
    "    for i in range(len(home_pred)):\n",
    "        # Check for NaN values and skip the calculation if found\n",
    "        if np.isnan(home_pred[i]) or np.isnan(away_pred[i]):\n",
    "            continue\n",
    "\n",
    "        home_rounded = home_pred[i]\n",
    "        away_rounded = away_pred[i]\n",
    "                \n",
    "        probability_matrix[i, 0] = skellam.cdf(-1, home_rounded, away_rounded)\n",
    "        probability_matrix[i, 1] = skellam.pmf(0, home_rounded, away_rounded)\n",
    "        probability_matrix[i, 2] = skellam.sf(0, home_rounded, away_rounded)\n",
    "        if(probability_matrix[i, 0] == np.nan or probability_matrix[i, 1] == np.nan or probability_matrix[i, 2] == np.nan):\n",
    "            print(\"NAN PRODUCED IN INDEX\", i)\n",
    "        \n",
    "    return probability_matrix\n",
    "\n",
    "def extract_poisson_probas_binary(home_pred, away_pred):\n",
    "    '''\n",
    "    creates a probability matrix according to the regression\n",
    "\n",
    "    Parameters:\n",
    "    home_pred: expected home score\n",
    "    away_pred: expected away score\n",
    "    '''\n",
    "\n",
    "    probability_matrix = np.zeros((len(home_pred), 2))  # 3 columns (-1, 0, 1 probabilities)\n",
    "    \n",
    "    for i in range(len(home_pred)):\n",
    "        # Check for NaN values and skip the calculation if found\n",
    "        if np.isnan(home_pred[i]) or np.isnan(away_pred[i]):\n",
    "            continue\n",
    "\n",
    "        home_rounded = home_pred[i]\n",
    "        away_rounded = away_pred[i]\n",
    "                \n",
    "        probability_matrix[i, 0] = skellam.cdf(-1, home_rounded, away_rounded)\n",
    "        probability_matrix[i, 1] = skellam.sf(-1, home_rounded, away_rounded)\n",
    "        if(probability_matrix[i, 0] == np.nan or probability_matrix[i, 1] == np.nan):\n",
    "            print(\"NAN PRODUCED IN INDEX\", i)\n",
    "        \n",
    "    return probability_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import poisson\n",
    "def get_lineups_and_predict(match, fifa, no_home_adv = False):\n",
    "    train = pipeline(match, fifa)\n",
    "\n",
    "    #when using random forest\n",
    "\n",
    "    example = pd.read_csv(\"X_test.csv\")\n",
    "    cols = example.columns\n",
    "    home_reg = RandomForestRegressor()\n",
    "    away_reg = RandomForestRegressor()\n",
    "    print(cols)\n",
    "\n",
    "    with open('encoder', 'rb') as file:\n",
    "        enc = pickle.load(file)\n",
    "    with open('RFAway.pkl', 'rb') as x:\n",
    "        away_reg = pickle.load(x)\n",
    "    with open('RFHome.pkl', 'rb') as x:\n",
    "        home_reg = pickle.load(x)\n",
    "    print(\"loaded models and encoder\")\n",
    "    # home_reg = XGBRegressor()\n",
    "    # home_reg.load_model(\"XGBHome.json\")\n",
    "    # features = home_reg.get_booster().feature_names\n",
    "    # away_reg = XGBRegressor()\n",
    "    # away_reg.load_model(\"XGBAway.json\")\n",
    "    fixtures = list(train['home_team_name'] + ' V '+train['away_team_name'])\n",
    "\n",
    "    print(fixtures)\n",
    "    #pre processing\n",
    "    #train.drop(['home_formation', 'away_fromation'], axis=1, inplace=True)\n",
    "    train[\"Home_min_max\"] = train['HomePlayer_Overall_max'] * train['HomePlayer_Overall_min']\n",
    "    train['Away_min_max'] = train['AwayPlayer_Overall_max'] * train['AwayPlayer_Overall_min']\n",
    "    train['HomelogOVR'] = np.log(train['HomePlayer_Overall_mean'])\n",
    "    train['AwaylogOVR'] = np.log(train['AwayPlayer_Overall_mean'])\n",
    "    # One-hot encode 'home_team_name'\n",
    "    encoded = enc.transform(train[['home_team_name', 'away_team_name']])\n",
    "    encoded_df = pd.DataFrame(encoded, columns=enc.get_feature_names_out(['home_team_name', 'away_team_name']))\n",
    "    train = pd.concat([encoded_df, train], axis=1)\n",
    "\n",
    "    train.drop(['home_team_name', 'away_team_name'], axis=1, inplace=True)\n",
    "    print('finished encoding')\n",
    "#    train = train[features]\n",
    "    features = cols\n",
    "    train = train[features]\n",
    "    train.drop('Unnamed: 0', axis=1,inplace=True) # when using rf\n",
    "\n",
    "    for col in train.columns:\n",
    "        train[col] = train[col].astype(float)\n",
    "\n",
    "    #train = train[away_reg.get_booster().feature_names]\n",
    "    home_pred = home_reg.predict(train)\n",
    "    away_pred = away_reg.predict(train)\n",
    "    if no_home_adv:\n",
    "        canon = train.copy()\n",
    "        for col in train.columns:\n",
    "            if \"Home\" in col:\n",
    "                canon['Away'+col[4:]] = train[col]\n",
    "            if \"Away\" in col:\n",
    "                canon['Home'+col[4:]] = train[col]\n",
    "            if 'home' in col:\n",
    "                canon['away'+col[4:]] = train[col]\n",
    "            if 'away' in col:\n",
    "                canon['home'+col[4:]] = train[col]\n",
    "        canon['B365H'] = train['B365A']\n",
    "        canon['B365A'] = train['B365H']\n",
    "        canon=canon[train.columns]\n",
    "        home_pred += home_reg.predict(canon)\n",
    "        home_pred/=2\n",
    "        away_pred += away_reg.predict(canon)\n",
    "        away_pred/=2\n",
    "\n",
    "    home_chances = np.zeros(len(home_pred))\n",
    "    away_chances = np.zeros(len(home_pred))\n",
    "    for i in range(len(home_pred)):\n",
    "        home_score = poisson(home_pred[i])\n",
    "        away_score = poisson(away_pred[i])\n",
    "        home_chances[i] = 1 - home_score.pmf(0)\n",
    "        away_chances[i] = 1 - away_score.pmf(0)\n",
    "\n",
    "    print(\"Home expected goals:\", home_pred)\n",
    "    print(\"Away expected goals:\", away_pred)\n",
    "    # add np arrays of proba to score\n",
    "    probas = extract_poisson_probas_binary(home_pred, away_pred)\n",
    "    print('Expected outcomes:')\n",
    "    outcomes = probas * np.asarray(train[['B365A',  'B365H']])\n",
    "    print(\"win outcomes\", outcomes[:,1])\n",
    "    print(\"loss / draw outcomes\", outcomes[:,0])\n",
    "    df = pd.DataFrame({'Fixture' : fixtures,\n",
    "                       \"Home Expected Goals\": home_pred,\n",
    "                       \"Away Expected Goals\": away_pred,\n",
    "                       'Home Expected' : outcomes[:, 1],\n",
    "                       'Away Expected' : outcomes[:, 0],\n",
    "                       \"Home Proba\" : probas[:, 1],\n",
    "                       \"Away/draw Proba\" : probas[:, 0],\n",
    "                       \"Home Chance to score\" : home_chances,\n",
    "                       \"Away Chance to score\" : away_chances,\n",
    "                       \"Best bet by sqrt (0 - away, 1 - draw, 2 - home team)\": np.argmax(probas*np.sqrt(np.asarray(train[['B365A',  'B365H']])), \n",
    "                       axis = 1),\n",
    "                       \"Best bet by ln  (0 - away, 1 - draw, 2 - home team)\": np.argmax(probas*np.log(np.asarray(train[['B365A', 'B365H']])), \n",
    "                       axis = 1),\n",
    "                       \"Best bet by sqrt -1  (0 - away, 1 - draw, 2 - home team)\": np.argmax(probas*np.sqrt(np.asarray(train[['B365A', 'B365H']]) -1), \n",
    "                       axis = 1)})\n",
    "    df.to_csv(\"predictions.csv\")\n",
    "    return probas\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-51712b4d4939>:219: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ratings_df = pd.read_csv(fifa,encoding='latin1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['player_id', 'player_url', 'fifa_version', 'fifa_update',\n",
      "       'update_as_of', 'Known As', 'Full Name', 'player_positions', 'Overall',\n",
      "       'potential',\n",
      "       ...\n",
      "       'ldm', 'cdm', 'rdm', 'rwb', 'lb', 'lcb', 'cb', 'rcb', 'rb', 'gk'],\n",
      "      dtype='object', length=109)\n",
      "[]\n",
      "Finished Loading test\n",
      "finished pipeline\n",
      "Index(['Unnamed: 0', 'HomePlayer_Overall_sd', 'HomePlayer_Overall_mean_ln',\n",
      "       'AwayPlayer_Overall_sd', 'AwayPlayer_Overall_mean_ln', 'home_GD_form',\n",
      "       'home_Points_form', 'away_GD_form', 'away_Points_form', 'B365A',\n",
      "       'B365D', 'B365H'],\n",
      "      dtype='object')\n",
      "loaded models and encoder\n",
      "['Manchester City V Arsenal']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- league\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a2bf9402ab79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_lineups_and_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'format.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fifa_season.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_home_adv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-905686d1be6a>\u001b[0m in \u001b[0;36mget_lineups_and_predict\u001b[1;34m(match, fifa, no_home_adv)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'AwaylogOVR'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'AwayPlayer_Overall_mean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# One-hot encode 'home_team_name'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mencoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'home_team_name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'away_team_name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'league'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mencoded_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'home_team_name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'away_team_name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'league'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mencoded_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Yuval\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[0mdata_to_wrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[1;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Yuval\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    875\u001b[0m             \u001b[1;34m\"infrequent_if_exist\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m         }\n\u001b[1;32m--> 877\u001b[1;33m         X_int, X_mask = self._transform(\n\u001b[0m\u001b[0;32m    878\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m             \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Yuval\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"error\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn_on_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     ):\n\u001b[1;32m--> 154\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         X_list, n_samples, n_features = self._check_X(\n",
      "\u001b[1;32mc:\\Users\\Yuval\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    460\u001b[0m                 )\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     def _validate_data(\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- league\n"
     ]
    }
   ],
   "source": [
    "get_lineups_and_predict('format.csv', 'fifa_season.csv', no_home_adv=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
